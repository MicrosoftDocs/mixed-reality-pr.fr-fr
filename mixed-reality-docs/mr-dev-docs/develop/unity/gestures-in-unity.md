---
title: Mouvements dans Unity
description: Apprenez à agir sur votre point de regard avec l’entrée de mouvement main à l’aide de XR et des API de bouton et d’axe courantes.
author: hferrone
ms.author: alexturn
ms.date: 12/1/2020
ms.topic: article
keywords: mouvements, Unity, point d’entrée, casque de réalité mixte, casque de réalité Windows mixte, casque de réalité virtuelle, MRTK, boîte à outils de réalité mixte
ms.openlocfilehash: 523f05f9b3dd05a140bb40168b654a2dc0b00bb5
ms.sourcegitcommit: 1c9035487270af76c6eaba11b11f6fc56c008135
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 04/13/2021
ms.locfileid: "107299714"
---
# <a name="gestures-in-unity"></a><span data-ttu-id="0c69f-104">Mouvements dans Unity</span><span class="sxs-lookup"><span data-stu-id="0c69f-104">Gestures in Unity</span></span>

<span data-ttu-id="0c69f-105">Il existe deux façons principales d’agir sur votre point [de regard](gaze-in-unity.md), les [gestes manuels](../../design/gaze-and-commit.md#composite-gestures) et les [contrôleurs de mouvement](../../design/motion-controllers.md) dans HoloLens et les HMD immersifs.</span><span class="sxs-lookup"><span data-stu-id="0c69f-105">There are two key ways to take action on your [gaze in Unity](gaze-in-unity.md), [hand gestures](../../design/gaze-and-commit.md#composite-gestures) and [motion controllers](../../design/motion-controllers.md) in HoloLens and Immersive HMD.</span></span> <span data-ttu-id="0c69f-106">Vous accédez aux données des deux sources d’entrée spatiale via les mêmes API dans Unity.</span><span class="sxs-lookup"><span data-stu-id="0c69f-106">You access the data for both sources of spatial input through the same APIs in Unity.</span></span>

<span data-ttu-id="0c69f-107">Unity fournit deux méthodes principales pour accéder aux données d’entrée spatiale pour Windows Mixed Reality.</span><span class="sxs-lookup"><span data-stu-id="0c69f-107">Unity provides two primary ways to access spatial input data for Windows Mixed Reality.</span></span> <span data-ttu-id="0c69f-108">Les API *d’entrée. GetButton/Input. GetAxis* courantes fonctionnent sur plusieurs kits de développement logiciel (SDK) XR, tandis que l’API *InteractionManager/GestureRecognizer* propre à Windows Mixed Reality expose l’ensemble complet des données d’entrée spatiale.</span><span class="sxs-lookup"><span data-stu-id="0c69f-108">The common *Input.GetButton/Input.GetAxis* APIs work across multiple Unity XR SDKs, while the *InteractionManager/GestureRecognizer* API specific to Windows Mixed Reality exposes the full set of spatial input data.</span></span>

## <a name="high-level-composite-gesture-apis-gesturerecognizer"></a><span data-ttu-id="0c69f-109">API de mouvement composite de haut niveau (GestureRecognizer)</span><span class="sxs-lookup"><span data-stu-id="0c69f-109">High-level composite gesture APIs (GestureRecognizer)</span></span>

<span data-ttu-id="0c69f-110">**Espace de noms :** *UnityEngine. XR. WSA. Input*</span><span class="sxs-lookup"><span data-stu-id="0c69f-110">**Namespace:** *UnityEngine.XR.WSA.Input*</span></span><br>
<span data-ttu-id="0c69f-111">**Types**: *GestureRecognizer*, *GestureSettings*, *InteractionSourceKind*</span><span class="sxs-lookup"><span data-stu-id="0c69f-111">**Types**: *GestureRecognizer*, *GestureSettings*, *InteractionSourceKind*</span></span>

<span data-ttu-id="0c69f-112">Votre application peut également reconnaître les gestes composites de niveau supérieur pour les sources d’entrée spatiale, le TAP, le maintien, la manipulation et les gestes de navigation.</span><span class="sxs-lookup"><span data-stu-id="0c69f-112">Your app can also recognize higher-level composite gestures for spatial input sources, Tap, Hold, Manipulation, and Navigation gestures.</span></span> <span data-ttu-id="0c69f-113">Vous pouvez reconnaître ces gestes composites sur les [mains](../../design/gaze-and-commit.md#composite-gestures) et les [contrôleurs de mouvement](../../design/motion-controllers.md) à l’aide de GestureRecognizer.</span><span class="sxs-lookup"><span data-stu-id="0c69f-113">You can recognize these composite gestures across both [hands](../../design/gaze-and-commit.md#composite-gestures) and [motion controllers](../../design/motion-controllers.md) using the GestureRecognizer.</span></span>

<span data-ttu-id="0c69f-114">Chaque événement de mouvement sur le GestureRecognizer fournit le SourceKind pour l’entrée, ainsi que le rayon de l’en-tête de ciblage au moment de l’événement.</span><span class="sxs-lookup"><span data-stu-id="0c69f-114">Each Gesture event on the GestureRecognizer provides the SourceKind for the input as well as the targeting head ray at the time of the event.</span></span> <span data-ttu-id="0c69f-115">Certains événements fournissent des informations supplémentaires spécifiques au contexte.</span><span class="sxs-lookup"><span data-stu-id="0c69f-115">Some events provide additional context-specific information.</span></span>

<span data-ttu-id="0c69f-116">Seules quelques étapes sont requises pour capturer des mouvements à l’aide d’un module de reconnaissance de mouvement :</span><span class="sxs-lookup"><span data-stu-id="0c69f-116">There are only a few steps required to capture gestures using a Gesture Recognizer:</span></span>
1. <span data-ttu-id="0c69f-117">Créer un module de reconnaissance de mouvement</span><span class="sxs-lookup"><span data-stu-id="0c69f-117">Create a new Gesture Recognizer</span></span>
2. <span data-ttu-id="0c69f-118">Spécifier les gestes à surveiller</span><span class="sxs-lookup"><span data-stu-id="0c69f-118">Specify which gestures to watch for</span></span>
3. <span data-ttu-id="0c69f-119">S’abonner à des événements pour ces mouvements</span><span class="sxs-lookup"><span data-stu-id="0c69f-119">Subscribe to events for those gestures</span></span>
4. <span data-ttu-id="0c69f-120">Démarrer la capture des mouvements</span><span class="sxs-lookup"><span data-stu-id="0c69f-120">Start capturing gestures</span></span>

### <a name="create-a-new-gesture-recognizer"></a><span data-ttu-id="0c69f-121">Créer un module de reconnaissance de mouvement</span><span class="sxs-lookup"><span data-stu-id="0c69f-121">Create a new Gesture Recognizer</span></span>

<span data-ttu-id="0c69f-122">Pour utiliser *GestureRecognizer*, vous devez avoir créé un *GestureRecognizer*:</span><span class="sxs-lookup"><span data-stu-id="0c69f-122">To use the *GestureRecognizer*, you must have created a *GestureRecognizer*:</span></span>

```cs
GestureRecognizer recognizer = new GestureRecognizer();
```

### <a name="specify-which-gestures-to-watch-for"></a><span data-ttu-id="0c69f-123">Spécifier les gestes à surveiller</span><span class="sxs-lookup"><span data-stu-id="0c69f-123">Specify which gestures to watch for</span></span>

<span data-ttu-id="0c69f-124">Spécifiez les gestes qui vous intéressent via *SetRecognizableGestures ()*:</span><span class="sxs-lookup"><span data-stu-id="0c69f-124">Specify which gestures you're interested in via *SetRecognizableGestures()*:</span></span>

```cs
recognizer.SetRecognizableGestures(GestureSettings.Tap | GestureSettings.Hold);
```

### <a name="subscribe-to-events-for-those-gestures"></a><span data-ttu-id="0c69f-125">S’abonner à des événements pour ces mouvements</span><span class="sxs-lookup"><span data-stu-id="0c69f-125">Subscribe to events for those gestures</span></span>

<span data-ttu-id="0c69f-126">Abonnez-vous aux événements pour les mouvements qui vous intéressent.</span><span class="sxs-lookup"><span data-stu-id="0c69f-126">Subscribe to events for the gestures you're interested in.</span></span>

```cs
void Start()
{
    recognizer.Tapped += GestureRecognizer_Tapped;
    recognizer.HoldStarted += GestureRecognizer_HoldStarted;
    recognizer.HoldCompleted += GestureRecognizer_HoldCompleted;
    recognizer.HoldCanceled += GestureRecognizer_HoldCanceled;
}
```

>[!NOTE]
><span data-ttu-id="0c69f-127">Les mouvements de navigation et de manipulation s’excluent mutuellement sur une instance d’un *GestureRecognizer*.</span><span class="sxs-lookup"><span data-stu-id="0c69f-127">Navigation and Manipulation gestures are mutually exclusive on an instance of a *GestureRecognizer*.</span></span>

### <a name="start-capturing-gestures"></a><span data-ttu-id="0c69f-128">Démarrer la capture des mouvements</span><span class="sxs-lookup"><span data-stu-id="0c69f-128">Start capturing gestures</span></span>

<span data-ttu-id="0c69f-129">Par défaut, un *GestureRecognizer* n’analyse pas l’entrée tant que *StartCapturingGestures ()* n’est pas appelé.</span><span class="sxs-lookup"><span data-stu-id="0c69f-129">By default, a *GestureRecognizer* doesn't monitor input until *StartCapturingGestures()* is called.</span></span> <span data-ttu-id="0c69f-130">Il est possible qu’un événement de mouvement soit généré après l’appel de *StopCapturingGestures ()* si l’entrée a été effectuée avant le frame dans lequel *StopCapturingGestures ()* a été traité.</span><span class="sxs-lookup"><span data-stu-id="0c69f-130">It's possible that a gesture event may be generated after *StopCapturingGestures()* is called if input was performed before the frame where *StopCapturingGestures()* was processed.</span></span> <span data-ttu-id="0c69f-131">Le *GestureRecognizer* se souvient s’il était activé ou désactivé au cours de la trame précédente dans laquelle le mouvement s’est réellement produit. il est donc fiable pour démarrer et arrêter la surveillance des mouvements en fonction du point de vue du regard de ce frame.</span><span class="sxs-lookup"><span data-stu-id="0c69f-131">The *GestureRecognizer* will remember whether it was on or off during the previous frame in which the gesture actually occurred, and so it's reliable to start and stop gesture monitoring based on this frame's gaze targeting.</span></span>

```cs
recognizer.StartCapturingGestures();
```

### <a name="stop-capturing-gestures"></a><span data-ttu-id="0c69f-132">Arrêter la capture des mouvements</span><span class="sxs-lookup"><span data-stu-id="0c69f-132">Stop capturing gestures</span></span>

<span data-ttu-id="0c69f-133">Pour arrêter la reconnaissance des mouvements :</span><span class="sxs-lookup"><span data-stu-id="0c69f-133">To stop gesture recognition:</span></span>

```cs
recognizer.StopCapturingGestures();
```

### <a name="removing-a-gesture-recognizer"></a><span data-ttu-id="0c69f-134">Suppression d’un module de reconnaissance de mouvement</span><span class="sxs-lookup"><span data-stu-id="0c69f-134">Removing a gesture recognizer</span></span>

<span data-ttu-id="0c69f-135">N’oubliez pas de vous désabonner des événements souscrits avant de détruire un objet *GestureRecognizer* .</span><span class="sxs-lookup"><span data-stu-id="0c69f-135">Remember to unsubscribe from subscribed events before destroying a *GestureRecognizer* object.</span></span>

```cs
void OnDestroy()
{
    recognizer.Tapped -= GestureRecognizer_Tapped;
    recognizer.HoldStarted -= GestureRecognizer_HoldStarted;
    recognizer.HoldCompleted -= GestureRecognizer_HoldCompleted;
    recognizer.HoldCanceled -= GestureRecognizer_HoldCanceled;
}
```

## <a name="rendering-the-motion-controller-model-in-unity"></a><span data-ttu-id="0c69f-136">Rendu du modèle de contrôleur de mouvement dans Unity</span><span class="sxs-lookup"><span data-stu-id="0c69f-136">Rendering the motion controller model in Unity</span></span>

<span data-ttu-id="0c69f-137">![Modèle de contrôleur de mouvement et téléportage](images/motioncontrollertest-teleport-1000px.png)</span><span class="sxs-lookup"><span data-stu-id="0c69f-137">![Motion Controller model and teleportation](images/motioncontrollertest-teleport-1000px.png)</span></span><br>
<span data-ttu-id="0c69f-138">*Modèle de contrôleur de mouvement et téléportage*</span><span class="sxs-lookup"><span data-stu-id="0c69f-138">*Motion controller model and teleportation*</span></span>

<span data-ttu-id="0c69f-139">Pour afficher les contrôleurs de mouvement de votre application qui correspondent aux contrôleurs physiques que vos utilisateurs détiennent et qui s’articulent à mesure que les différents boutons sont enfoncés, vous pouvez utiliser la **Prefab MotionController** dans le [Toolkit de réalité mixte](https://github.com/Microsoft/MixedRealityToolkit-Unity/).</span><span class="sxs-lookup"><span data-stu-id="0c69f-139">To render motion controllers in your app that match the physical controllers your users are holding and articulate as various buttons are pressed, you can use the **MotionController prefab** in the [Mixed Reality Toolkit](https://github.com/Microsoft/MixedRealityToolkit-Unity/).</span></span>  <span data-ttu-id="0c69f-140">Ce Prefab charge dynamiquement le modèle glTF correct au moment de l’exécution à partir du pilote du contrôleur de mouvement installé du système.</span><span class="sxs-lookup"><span data-stu-id="0c69f-140">This prefab dynamically loads the correct glTF model at runtime from the system's installed motion controller driver.</span></span>  <span data-ttu-id="0c69f-141">Il est important de charger ces modèles de manière dynamique plutôt que de les importer manuellement dans l’éditeur, afin que votre application affiche des modèles 3D physiquement précis pour tous les contrôleurs actuels et futurs que vos utilisateurs peuvent avoir.</span><span class="sxs-lookup"><span data-stu-id="0c69f-141">It's important to load these models dynamically rather than importing them manually in the editor, so that your app will show physically accurate 3D models for any current and future controllers your users may have.</span></span>

1. <span data-ttu-id="0c69f-142">Suivez les instructions [prise en main](https://github.com/Microsoft/MixedRealityToolkit-Unity/blob/htk_release/GettingStarted.md) pour télécharger la boîte à outils de réalité mixte et l’ajouter à votre projet Unity.</span><span class="sxs-lookup"><span data-stu-id="0c69f-142">Follow the [Getting Started](https://github.com/Microsoft/MixedRealityToolkit-Unity/blob/htk_release/GettingStarted.md) instructions to download the Mixed Reality Toolkit and add it to your Unity project.</span></span>
2. <span data-ttu-id="0c69f-143">Si vous avez remplacé votre appareil photo par le *MixedRealityCameraParent* Prefab dans le cadre des étapes de prise en main, vous êtes en déplacement.</span><span class="sxs-lookup"><span data-stu-id="0c69f-143">If you replaced your camera with the *MixedRealityCameraParent* prefab as part of the Getting Started steps, you're good to go!</span></span>  <span data-ttu-id="0c69f-144">Prefab comprend le rendu du contrôleur de mouvement.</span><span class="sxs-lookup"><span data-stu-id="0c69f-144">That prefab includes motion controller rendering.</span></span>  <span data-ttu-id="0c69f-145">Sinon, ajoutez *Assets/HoloToolkit/Input/Prefabs/MotionControllers. Prefab* à votre scène à partir du volet de projet.</span><span class="sxs-lookup"><span data-stu-id="0c69f-145">Otherwise, add *Assets/HoloToolkit/Input/Prefabs/MotionControllers.prefab* into your scene from the Project pane.</span></span>  <span data-ttu-id="0c69f-146">Vous pouvez ajouter ce Prefab en tant qu’enfant de n’importe quel objet parent que vous utilisez pour déplacer la caméra lorsque l’utilisateur téléporte dans votre scène, afin que les contrôleurs soient fournis avec l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="0c69f-146">You'll want to add that prefab as a child of whatever parent object you use to move the camera around when the user teleports within your scene, so that the controllers come along with the user.</span></span>  <span data-ttu-id="0c69f-147">Si votre application n’implique pas de téléportage, ajoutez simplement le Prefab à la racine de votre scène.</span><span class="sxs-lookup"><span data-stu-id="0c69f-147">If your app doesn't involve teleporting, just add the prefab at the root of your scene.</span></span>

## <a name="throwing-objects"></a><span data-ttu-id="0c69f-148">Lever des objets</span><span class="sxs-lookup"><span data-stu-id="0c69f-148">Throwing objects</span></span>

<span data-ttu-id="0c69f-149">La levée d’objets dans la réalité virtuelle est un problème plus difficile qu’il n’y paraît d’abord.</span><span class="sxs-lookup"><span data-stu-id="0c69f-149">Throwing objects in virtual reality is a harder problem than it may at first seem.</span></span> <span data-ttu-id="0c69f-150">Comme avec la plupart des interactions basées physiquement, lorsque la levée dans le jeu se fait de manière inattendue, elle est immédiatement évidente et s’interrompt.</span><span class="sxs-lookup"><span data-stu-id="0c69f-150">As with most physically based interactions, when throwing in game acts in an unexpected way, it's immediately obvious and breaks immersion.</span></span> <span data-ttu-id="0c69f-151">Nous avons passé un peu de temps à réfléchir à la façon de représenter un comportement de levée de manière physique et à rencontrer quelques recommandations, activées par le biais des mises à jour de notre plateforme, que nous aimerions partager avec vous.</span><span class="sxs-lookup"><span data-stu-id="0c69f-151">We've spent some time thinking deeply about how to represent a physically correct throwing behavior, and have come up with a few guidelines, enabled through updates to our platform, that we would like to share with you.</span></span>

<span data-ttu-id="0c69f-152">Vous trouverez un exemple de la façon dont nous vous recommandons d’implémenter la levée [ici](https://github.com/keluecke/MixedRealityToolkit-Unity/blob/master/External/Unitypackages/ThrowingStarter.unitypackage).</span><span class="sxs-lookup"><span data-stu-id="0c69f-152">You can find an example of how we recommend to implement throwing [here](https://github.com/keluecke/MixedRealityToolkit-Unity/blob/master/External/Unitypackages/ThrowingStarter.unitypackage).</span></span> <span data-ttu-id="0c69f-153">Cet exemple suit les quatre instructions suivantes :</span><span class="sxs-lookup"><span data-stu-id="0c69f-153">This sample follows these four guidelines:</span></span>
* <span data-ttu-id="0c69f-154">**Utilisez la *vélocité* du contrôleur au lieu de la position**.</span><span class="sxs-lookup"><span data-stu-id="0c69f-154">**Use the controller’s *velocity* instead of position**.</span></span> <span data-ttu-id="0c69f-155">Dans la mise à jour de novembre de Windows, nous avons introduit un changement de comportement dans l' [État de suivi positionnel « approximatif](../../design/motion-controllers.md#controller-tracking-state)».</span><span class="sxs-lookup"><span data-stu-id="0c69f-155">In the November update to Windows, we introduced a change in behavior when in the [''Approximate'' positional tracking state](../../design/motion-controllers.md#controller-tracking-state).</span></span> <span data-ttu-id="0c69f-156">Dans cet État, les informations de vélocité sur le contrôleur continuent d’être signalées aussi longtemps que nous pensons qu’il s’agit d’une précision élevée, qui est souvent plus longue que la position demeure une précision élevée.</span><span class="sxs-lookup"><span data-stu-id="0c69f-156">When in this state, velocity information about the controller will continue to be reported for as long as we believe its high accuracy, which is often longer than position remains high accuracy.</span></span>
* <span data-ttu-id="0c69f-157">**Incorporez la *vélocité angulaire* du contrôleur**.</span><span class="sxs-lookup"><span data-stu-id="0c69f-157">**Incorporate the *angular velocity* of the controller**.</span></span> <span data-ttu-id="0c69f-158">Cette logique est contenue dans le `throwing.cs` fichier de la `GetThrownObjectVelAngVel` méthode statique, dans le package lié ci-dessus :</span><span class="sxs-lookup"><span data-stu-id="0c69f-158">This logic is all contained in the `throwing.cs` file in the `GetThrownObjectVelAngVel` static method, within the package linked above:</span></span>
   1. <span data-ttu-id="0c69f-159">Comme la vélocité angulaire est conservée, l’objet levé doit conserver la même vélocité angulaire qu’au moment de la levée : `objectAngularVelocity = throwingControllerAngularVelocity;`</span><span class="sxs-lookup"><span data-stu-id="0c69f-159">As angular velocity is conserved, the thrown object must maintain the same angular velocity as it had at the moment of the throw: `objectAngularVelocity = throwingControllerAngularVelocity;`</span></span>
   2. <span data-ttu-id="0c69f-160">Comme le centre de la masse de l’objet levé n’est probablement pas à l’origine de la poignée, il a probablement une vitesse différente de celle du contrôleur dans le cadre de la référence de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="0c69f-160">As the center of mass of the thrown object is likely not at the origin of the grip pose, it likely has a different velocity than that of the controller in the frame of reference of the user.</span></span> <span data-ttu-id="0c69f-161">La partie de la rapidité de l’objet utilisée de cette façon est la vélocité tangentielle instantanée du centre de la masse de l’objet levé autour de l’origine du contrôleur.</span><span class="sxs-lookup"><span data-stu-id="0c69f-161">The portion of the object’s velocity contributed in this way is the instantaneous tangential velocity of the center of mass of the thrown object around the controller origin.</span></span> <span data-ttu-id="0c69f-162">Cette vélocité tangentielle est le produit croisé de la vélocité angulaire du contrôleur avec le vecteur représentant la distance entre l’origine du contrôleur et le centre de la masse de l’objet levé.</span><span class="sxs-lookup"><span data-stu-id="0c69f-162">This tangential velocity is the cross product of the angular velocity of the controller with the vector representing the distance between the controller origin and the center of mass of the thrown object.</span></span>

      ```cs
      Vector3 radialVec = thrownObjectCenterOfMass - throwingControllerPos;
      Vector3 tangentialVelocity = Vector3.Cross(throwingControllerAngularVelocity, radialVec);
      ```

   3. <span data-ttu-id="0c69f-163">La vélocité totale de l’objet levé est la somme de la vélocité du contrôleur et de cette vélocité tangentielle : `objectVelocity = throwingControllerVelocity + tangentialVelocity;`</span><span class="sxs-lookup"><span data-stu-id="0c69f-163">The total velocity of the thrown object is the sum of velocity of the controller and this tangential velocity: `objectVelocity = throwingControllerVelocity + tangentialVelocity;`</span></span>

* <span data-ttu-id="0c69f-164">**Portez une attention particulière à l' *heure* à laquelle nous appliquons la vélocité**.</span><span class="sxs-lookup"><span data-stu-id="0c69f-164">**Pay close attention to the *time* at which we apply the velocity**.</span></span> <span data-ttu-id="0c69f-165">Quand vous appuyez sur un bouton, il peut falloir jusqu’à 20 ms pour que cet événement se propage via Bluetooth au système d’exploitation.</span><span class="sxs-lookup"><span data-stu-id="0c69f-165">When a button is pressed, it can take up to 20 ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="0c69f-166">Cela signifie que si vous interrogez une modification de l’état d’un contrôleur en l’appuyant sur non enfoncé ou sur l’autre, le contrôleur vous pose les informations dont vous bénéficiez en effet.</span><span class="sxs-lookup"><span data-stu-id="0c69f-166">This means that if you poll for a controller state change from pressed to not pressed or the other way around, the controller pose information you get with it will actually be ahead of this change in state.</span></span> <span data-ttu-id="0c69f-167">En outre, la présentation du contrôleur présentée par notre API d’interrogation est anticipée afin de refléter une situation probable au moment où l’image sera affichée, ce qui peut être supérieur à 20 ms à l’avenir.</span><span class="sxs-lookup"><span data-stu-id="0c69f-167">Further, the controller pose presented by our polling API is forward predicted to reflect a likely pose at the time the frame will be displayed which could be more than 20 ms in the future.</span></span> <span data-ttu-id="0c69f-168">Cela est idéal pour le *rendu* des objets détenus, mais il compose notre problème de temps pour *cibler* l’objet à mesure que nous calculons la trajectoire pour le moment où l’utilisateur a relâché la levée.</span><span class="sxs-lookup"><span data-stu-id="0c69f-168">This is good for *rendering* held objects, but compounds our time problem for *targeting* the object as we calculate the trajectory for the moment the user released the throw.</span></span> <span data-ttu-id="0c69f-169">Heureusement, avec la mise à jour de novembre, lors de l’envoi d’un événement Unity comme *InteractionSourcePressed* ou *InteractionSourceReleased* , l’état contient les données de la pose de l’historique de retour lorsque le bouton était enfoncé ou relâché.</span><span class="sxs-lookup"><span data-stu-id="0c69f-169">Fortunately, with the November update, when a Unity event like *InteractionSourcePressed* or *InteractionSourceReleased* is sent, the state includes the historical pose data from back when the button was pressed or released.</span></span>  <span data-ttu-id="0c69f-170">Pour optimiser le rendu du contrôleur et le ciblage du contrôleur lors des levées, vous devez utiliser correctement l’interrogation et l’événement, selon le cas :</span><span class="sxs-lookup"><span data-stu-id="0c69f-170">To get the most accurate controller rendering and controller targeting during throws, you must correctly use polling and eventing, as appropriate:</span></span>
   * <span data-ttu-id="0c69f-171">Pour le rendu de chaque trame par le **contrôleur** , votre application doit positionner les *gameobject* du contrôleur au niveau du contrôleur avant prédiction pour le temps des photons du frame actuel.</span><span class="sxs-lookup"><span data-stu-id="0c69f-171">For **controller rendering** each frame, your app should position the controller's *GameObject* at the forward-predicted controller pose for the current frame’s photon time.</span></span>  <span data-ttu-id="0c69f-172">Vous recevez ces données à partir d’API d’interrogation Unity, telles que *[XR. InputTracking. GetLocalPosition](https://docs.unity3d.com/ScriptReference/XR.InputTracking.GetLocalPosition.html)* ou *[XR. WSA. Entrez. InteractionManager. GetCurrentReading](https://docs.unity3d.com/ScriptReference/XR.WSA.Input.InteractionManager.GetCurrentReading.html)*.</span><span class="sxs-lookup"><span data-stu-id="0c69f-172">You get this data from Unity polling APIs like *[XR.InputTracking.GetLocalPosition](https://docs.unity3d.com/ScriptReference/XR.InputTracking.GetLocalPosition.html)* or *[XR.WSA.Input.InteractionManager.GetCurrentReading](https://docs.unity3d.com/ScriptReference/XR.WSA.Input.InteractionManager.GetCurrentReading.html)*.</span></span>
   * <span data-ttu-id="0c69f-173">Pour le **ciblage du contrôleur** sur une presse ou une mise en sortie, votre application doit raycast et calculer des trajectoires en fonction de la pose du contrôleur historique pour cet événement Press ou Release.</span><span class="sxs-lookup"><span data-stu-id="0c69f-173">For **controller targeting** upon a press or release, your app should raycast and calculate trajectories based on the historical controller pose for that press or release event.</span></span>  <span data-ttu-id="0c69f-174">Vous recevez ces données à partir d’API d’événements Unity, telles que *[InteractionManager. InteractionSourcePressed](https://docs.unity3d.com/ScriptReference/XR.WSA.Input.InteractionManager.InteractionSourcePressed.html)*.</span><span class="sxs-lookup"><span data-stu-id="0c69f-174">You get this data from Unity eventing APIs, like *[InteractionManager.InteractionSourcePressed](https://docs.unity3d.com/ScriptReference/XR.WSA.Input.InteractionManager.InteractionSourcePressed.html)*.</span></span>
* <span data-ttu-id="0c69f-175">**Utilisez la poignée**.</span><span class="sxs-lookup"><span data-stu-id="0c69f-175">**Use the grip pose**.</span></span> <span data-ttu-id="0c69f-176">La rapidité et la vélocité angulaires sont rapportées par rapport à la pose de la poignée, et non à la pose du pointeur.</span><span class="sxs-lookup"><span data-stu-id="0c69f-176">Angular velocity and velocity are reported relative to the grip pose, not pointer pose.</span></span>

<span data-ttu-id="0c69f-177">La génération continuera à s’améliorer avec les futures mises à jour de Windows, et vous pouvez vous attendre à trouver plus d’informations ici.</span><span class="sxs-lookup"><span data-stu-id="0c69f-177">Throwing will continue to improve with future Windows updates, and you can expect to find more information on it here.</span></span>

## <a name="gesture-and-motion-controllers-in-mrtk"></a><span data-ttu-id="0c69f-178">Contrôleurs de mouvement et de mouvement dans MRTK</span><span class="sxs-lookup"><span data-stu-id="0c69f-178">Gesture and Motion Controllers in MRTK</span></span>

<span data-ttu-id="0c69f-179">Vous pouvez accéder au contrôleur de mouvement et de mouvement à partir du gestionnaire d’entrée.</span><span class="sxs-lookup"><span data-stu-id="0c69f-179">You can access gesture and motion controller from the input Manager.</span></span>

* [<span data-ttu-id="0c69f-180">Mouvement dans MRTK</span><span class="sxs-lookup"><span data-stu-id="0c69f-180">Gesture in MRTK</span></span>](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/gestures)
* [<span data-ttu-id="0c69f-181">Contrôleur de mouvement dans MRTK</span><span class="sxs-lookup"><span data-stu-id="0c69f-181">Motion Controller in MRTK</span></span>](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/controllers)

## <a name="follow-along-with-tutorials"></a><span data-ttu-id="0c69f-182">Avancer avec des tutoriels</span><span class="sxs-lookup"><span data-stu-id="0c69f-182">Follow along with tutorials</span></span>

<span data-ttu-id="0c69f-183">Des didacticiels pas à pas, avec des exemples de personnalisation plus détaillés, sont disponibles dans Mixed Reality Academy :</span><span class="sxs-lookup"><span data-stu-id="0c69f-183">Step-by-step tutorials, with more detailed customization examples, are available in the Mixed Reality Academy:</span></span>

- [<span data-ttu-id="0c69f-184">Réalité mixte - Entrées - Cours 211 : Mouvement</span><span class="sxs-lookup"><span data-stu-id="0c69f-184">MR Input 211: Gesture</span></span>](tutorials/holograms-211.md)
- [<span data-ttu-id="0c69f-185">Réalité mixte - Entrées - Cours 213 : Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="0c69f-185">MR Input 213: Motion controllers</span></span>](../../deprecated/mixed-reality-213.md)

<span data-ttu-id="0c69f-186">[![Entrée MR 213-contrôleur de mouvement](images/mr213-main-600px.jpg)](/windows/mixed-reality/mixed-reality-213)</span><span class="sxs-lookup"><span data-stu-id="0c69f-186">[![MR Input 213 - Motion controller](images/mr213-main-600px.jpg)](/windows/mixed-reality/mixed-reality-213)</span></span><br>
<span data-ttu-id="0c69f-187">*Entrée MR 213-contrôleur de mouvement*</span><span class="sxs-lookup"><span data-stu-id="0c69f-187">*MR Input 213 - Motion controller*</span></span>

## <a name="next-development-checkpoint"></a><span data-ttu-id="0c69f-188">Point de contrôle de développement suivant</span><span class="sxs-lookup"><span data-stu-id="0c69f-188">Next Development Checkpoint</span></span>

<span data-ttu-id="0c69f-189">Si vous suivez le parcours de développement Unity que nous avons disposé, vous êtes au cœur de l’exploration des blocs de construction MRTK Core.</span><span class="sxs-lookup"><span data-stu-id="0c69f-189">If you're following the Unity development journey we've laid out, you're in the midst of exploring the MRTK core building blocks.</span></span> <span data-ttu-id="0c69f-190">À partir de là, vous pouvez passer au module suivant :</span><span class="sxs-lookup"><span data-stu-id="0c69f-190">From here, you can continue to the next building block:</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="0c69f-191">Suivi du regard et des mains</span><span class="sxs-lookup"><span data-stu-id="0c69f-191">Hand and eye tracking</span></span>](./hand-eye-in-unity.md)

<span data-ttu-id="0c69f-192">Ou accéder aux API et fonctionnalités de la plateforme Mixed Reality :</span><span class="sxs-lookup"><span data-stu-id="0c69f-192">Or jump to Mixed Reality platform capabilities and APIs:</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="0c69f-193">Expériences partagées</span><span class="sxs-lookup"><span data-stu-id="0c69f-193">Shared experiences</span></span>](shared-experiences-in-unity.md)

<span data-ttu-id="0c69f-194">Vous pouvez revenir aux [points de contrôle de développement Unity](unity-development-overview.md#2-core-building-blocks) à tout moment.</span><span class="sxs-lookup"><span data-stu-id="0c69f-194">You can always go back to the [Unity development checkpoints](unity-development-overview.md#2-core-building-blocks) at any time.</span></span>

## <a name="see-also"></a><span data-ttu-id="0c69f-195">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="0c69f-195">See also</span></span>

* [<span data-ttu-id="0c69f-196">Suivre de la tête et valider</span><span class="sxs-lookup"><span data-stu-id="0c69f-196">Head-gaze and commit</span></span>](../../design/gaze-and-commit.md)
* [<span data-ttu-id="0c69f-197">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="0c69f-197">Motion controllers</span></span>](../../design/motion-controllers.md)